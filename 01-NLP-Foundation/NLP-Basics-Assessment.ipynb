{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Basics Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this assessment we'll be using the short story [_An Occurrence at Owl Creek Bridge_](https://en.wikipedia.org/wiki/An_Occurrence_at_Owl_Creek_Bridge) by Ambrose Bierce (1890). <br>The story is in the public domain; the text file was obtained from [Project Gutenberg](https://www.gutenberg.org/ebooks/375.txt.utf-8)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS CELL to perform standard imports:\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Create a Doc object from the file `owlcreek.txt`**<br>\n",
    "> HINT: Use `with open('../TextFiles/owlcreek.txt') as f:`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code here:\n",
    "with open('../datasets/TextFiles/owlcreek.txt') as f:\n",
    "    d = f.read()#[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(d)\n",
    "type(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AN OCCURRENCE AT OWL CREEK BRIDGE\n",
       "\n",
       "by Ambrose Bierce\n",
       "\n",
       "I\n",
       "\n",
       "A man stood upon a railroad bridge in northern Alabama, looking down\n",
       "into the swift water twenty feet below.  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run this cell to verify it worked:\n",
    "doc[:36]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. How many tokens are contained in the file?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4835"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. How many sentences are contained in the file?**<br>HINT: You'll want to build a list first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "229"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([sent for sent in doc.sents])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Print the second sentence in the document**<br> HINT: Indexing starts at zero, and the title counts as the first sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I\\n\\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents = [sent for sent in doc.sents]\n",
    "\n",
    "sents[1].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 5. For each token in the sentence above, print its `text`, `POS` tag, `dep` tag and `lemma`<br>\n",
    "CHALLENGE: Have values line up in columns in the print output.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A  >>  NOUN  >>  det  >>  a\n",
      "\n",
      "  >>  SPACE  >>    >>  \n",
      "\n",
      "sentinel  >>  NOUN  >>  nsubj  >>  sentinel\n",
      "at  >>  ADP  >>  prep  >>  at\n",
      "each  >>  DET  >>  det  >>  each\n",
      "end  >>  NOUN  >>  pobj  >>  end\n",
      "of  >>  ADP  >>  prep  >>  of\n",
      "the  >>  DET  >>  det  >>  the\n",
      "bridge  >>  NOUN  >>  pobj  >>  bridge\n",
      "stood  >>  VERB  >>  ROOT  >>  stand\n",
      "with  >>  ADP  >>  prep  >>  with\n",
      "his  >>  DET  >>  poss  >>  -PRON-\n",
      "rifle  >>  NOUN  >>  pobj  >>  rifle\n",
      "in  >>  ADP  >>  prep  >>  in\n",
      "the  >>  DET  >>  det  >>  the\n",
      "\n",
      "  >>  SPACE  >>    >>  \n",
      "\n",
      "position  >>  NOUN  >>  pobj  >>  position\n",
      "known  >>  VERB  >>  acl  >>  know\n",
      "as  >>  SCONJ  >>  prep  >>  as\n",
      "\"  >>  PUNCT  >>  punct  >>  \"\n",
      "support  >>  NOUN  >>  pobj  >>  support\n",
      ",  >>  PUNCT  >>  punct  >>  ,\n",
      "\"  >>  PUNCT  >>  punct  >>  \"\n",
      "that  >>  DET  >>  nsubj  >>  that\n",
      "is  >>  AUX  >>  ccomp  >>  be\n",
      "to  >>  PART  >>  aux  >>  to\n",
      "say  >>  VERB  >>  xcomp  >>  say\n",
      ",  >>  PUNCT  >>  punct  >>  ,\n",
      "vertical  >>  ADJ  >>  acomp  >>  vertical\n",
      "in  >>  ADP  >>  prep  >>  in\n",
      "front  >>  NOUN  >>  pobj  >>  front\n",
      "of  >>  ADP  >>  prep  >>  of\n",
      "the  >>  DET  >>  det  >>  the\n",
      "\n",
      "  >>  SPACE  >>    >>  \n",
      "\n",
      "left  >>  ADJ  >>  amod  >>  left\n",
      "shoulder  >>  NOUN  >>  pobj  >>  shoulder\n",
      ",  >>  PUNCT  >>  punct  >>  ,\n",
      "the  >>  DET  >>  det  >>  the\n",
      "hammer  >>  NOUN  >>  nsubj  >>  hammer\n",
      "resting  >>  VERB  >>  nsubj  >>  rest\n",
      "on  >>  ADP  >>  prep  >>  on\n",
      "the  >>  DET  >>  det  >>  the\n",
      "forearm  >>  NOUN  >>  pobj  >>  forearm\n",
      "thrown  >>  VERB  >>  ccomp  >>  throw\n",
      "straight  >>  ADV  >>  advmod  >>  straight\n",
      "\n",
      "  >>  SPACE  >>    >>  \n",
      "\n",
      "across  >>  ADP  >>  prep  >>  across\n",
      "the  >>  DET  >>  det  >>  the\n",
      "chest  >>  NOUN  >>  pobj  >>  chest\n",
      "--  >>  PUNCT  >>  punct  >>  --\n",
      "a  >>  DET  >>  det  >>  a\n",
      "formal  >>  ADJ  >>  amod  >>  formal\n",
      "and  >>  CCONJ  >>  cc  >>  and\n",
      "unnatural  >>  ADJ  >>  conj  >>  unnatural\n",
      "position  >>  NOUN  >>  dobj  >>  position\n",
      ",  >>  PUNCT  >>  punct  >>  ,\n",
      "enforcing  >>  VERB  >>  advcl  >>  enforce\n",
      "an  >>  DET  >>  det  >>  an\n",
      "erect  >>  NOUN  >>  dobj  >>  erect\n",
      "\n",
      "  >>  SPACE  >>    >>  \n",
      "\n",
      "carriage  >>  NOUN  >>  appos  >>  carriage\n",
      "of  >>  ADP  >>  prep  >>  of\n",
      "the  >>  DET  >>  det  >>  the\n",
      "body  >>  NOUN  >>  pobj  >>  body\n",
      ".  >>  PUNCT  >>  punct  >>  .\n",
      "   >>  SPACE  >>    >>   \n"
     ]
    }
   ],
   "source": [
    "# NORMAL SOLUTION:\n",
    "\n",
    "for token in sents[10]:\n",
    "    print(token.text,' >> ', token.pos_, ' >> ', token.dep_, ' >> ', token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A                    NOUN       det        a         \n",
      "\n",
      "                    SPACE                 \n",
      "         \n",
      "sentinel             NOUN       nsubj      sentinel  \n",
      "at                   ADP        prep       at        \n",
      "each                 DET        det        each      \n",
      "end                  NOUN       pobj       end       \n",
      "of                   ADP        prep       of        \n",
      "the                  DET        det        the       \n",
      "bridge               NOUN       pobj       bridge    \n",
      "stood                VERB       ROOT       stand     \n",
      "with                 ADP        prep       with      \n",
      "his                  DET        poss       -PRON-    \n",
      "rifle                NOUN       pobj       rifle     \n",
      "in                   ADP        prep       in        \n",
      "the                  DET        det        the       \n",
      "\n",
      "                    SPACE                 \n",
      "         \n",
      "position             NOUN       pobj       position  \n",
      "known                VERB       acl        know      \n",
      "as                   SCONJ      prep       as        \n",
      "\"                    PUNCT      punct      \"         \n",
      "support              NOUN       pobj       support   \n",
      ",                    PUNCT      punct      ,         \n",
      "\"                    PUNCT      punct      \"         \n",
      "that                 DET        nsubj      that      \n",
      "is                   AUX        ccomp      be        \n",
      "to                   PART       aux        to        \n",
      "say                  VERB       xcomp      say       \n",
      ",                    PUNCT      punct      ,         \n",
      "vertical             ADJ        acomp      vertical  \n",
      "in                   ADP        prep       in        \n",
      "front                NOUN       pobj       front     \n",
      "of                   ADP        prep       of        \n",
      "the                  DET        det        the       \n",
      "\n",
      "                    SPACE                 \n",
      "         \n",
      "left                 ADJ        amod       left      \n",
      "shoulder             NOUN       pobj       shoulder  \n",
      ",                    PUNCT      punct      ,         \n",
      "the                  DET        det        the       \n",
      "hammer               NOUN       nsubj      hammer    \n",
      "resting              VERB       nsubj      rest      \n",
      "on                   ADP        prep       on        \n",
      "the                  DET        det        the       \n",
      "forearm              NOUN       pobj       forearm   \n",
      "thrown               VERB       ccomp      throw     \n",
      "straight             ADV        advmod     straight  \n",
      "\n",
      "                    SPACE                 \n",
      "         \n",
      "across               ADP        prep       across    \n",
      "the                  DET        det        the       \n",
      "chest                NOUN       pobj       chest     \n",
      "--                   PUNCT      punct      --        \n",
      "a                    DET        det        a         \n",
      "formal               ADJ        amod       formal    \n",
      "and                  CCONJ      cc         and       \n",
      "unnatural            ADJ        conj       unnatural \n",
      "position             NOUN       dobj       position  \n",
      ",                    PUNCT      punct      ,         \n",
      "enforcing            VERB       advcl      enforce   \n",
      "an                   DET        det        an        \n",
      "erect                NOUN       dobj       erect     \n",
      "\n",
      "                    SPACE                 \n",
      "         \n",
      "carriage             NOUN       appos      carriage  \n",
      "of                   ADP        prep       of        \n",
      "the                  DET        det        the       \n",
      "body                 NOUN       pobj       body      \n",
      ".                    PUNCT      punct      .         \n",
      "                     SPACE                           \n"
     ]
    }
   ],
   "source": [
    "# CHALLENGE SOLUTION:\n",
    "# NORMAL SOLUTION:\n",
    "\n",
    "for token in sents[10]:\n",
    "    print(f'{token.text:{20}} {token.pos_:{10}} {token.dep_:{10}} {token.lemma_:{10}}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Write a matcher called 'Swimming' that finds both occurrences of the phrase \"swimming vigorously\" in the text**<br>\n",
    "HINT: You should include an `'IS_SPACE': True` pattern between the two words!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Matcher library:\n",
    "\n",
    "from spacy.matcher import Matcher\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pattern and add it to matcher:\n",
    "\n",
    "\n",
    "pattern = [{'LOWER':'swimming'},{'IS_SPACE':True},{'LOWER':'vigorously'}]\n",
    "matcher.add('Swimming',None,pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(12881893835109366681, 1274, 1277), (12881893835109366681, 3609, 3612)]\n"
     ]
    }
   ],
   "source": [
    "# Create a list of matches called \"found_matches\" and print the list:\n",
    "\n",
    "found = matcher(doc)\n",
    "print(found)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. Print the text surrounding each found match**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By diving I could evade the bullets and, swimming\n",
      "vigorously, reach the bank, take to the woods and get away home\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over his shoulder; he was now swimming\n",
      "vigorously with the current.  \n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXTRA CREDIT:<br>Print the *sentence* that contains each found match**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By diving I could evade the bullets and, swimming\n",
      "vigorously, reach the bank, take to the woods and get away home.  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The hunted man saw all this over his shoulder; he was now swimming\n",
      "vigorously with the current.  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Great Job!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
