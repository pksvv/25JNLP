{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-learn Primer\n",
    "\n",
    "**Scikit-learn** (http://scikit-learn.org/) is an open-source machine learning library for Python that offers a variety of regression, classification and clustering algorithms.\n",
    "\n",
    "In this section we'll perform a fairly simple classification exercise with scikit-learn. In the next section we'll leverage the machine learning strength of scikit-learn to perform natural language classifications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation and Setup\n",
    "\n",
    "### From the command line or terminal:\n",
    "> `conda install scikit-learn`\n",
    "> <br>*or*<br>\n",
    "> `pip install -U scikit-learn`\n",
    "\n",
    "Scikit-learn additionally requires that NumPy and SciPy be installed. For more info visit http://scikit-learn.org/stable/install.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform Imports and Load Data\n",
    "For this exercise we'll be using the **SMSSpamCollection** dataset from [UCI datasets](https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection) that contains more than 5 thousand SMS phone messages.<br>You can check out the [**sms_readme**](../TextFiles/sms_readme.txt) file for more info.\n",
    "\n",
    "The file is a [tab-separated-values](https://en.wikipedia.org/wiki/Tab-separated_values) (tsv) file with four columns:\n",
    "> **label** - every message is labeled as either ***ham*** or ***spam***<br>\n",
    "> **message** - the message itself<br>\n",
    "> **length** - the number of characters in each message<br>\n",
    "> **punct** - the number of punctuation characters in each message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>length</th>\n",
       "      <th>punct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>111</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>155</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>49</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message  length  punct\n",
       "0   ham  Go until jurong point, crazy.. Available only ...     111      9\n",
       "1   ham                      Ok lar... Joking wif u oni...      29      6\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...     155      6\n",
       "3   ham  U dun say so early hor... U c already then say...      49      6\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...      61      2"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../datasets/TextFiles/smsspamcollection.tsv', sep='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5572"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for missing values:\n",
    "Machine learning models usually require complete data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label      0\n",
       "message    0\n",
       "length     0\n",
       "punct      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take a quick look at the *ham* and *spam* `label` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham', 'spam'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4825\n",
       "spam     747\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=green>We see that 4825 out of 5572 messages, or 86.6%, are ham.<br>This means that any machine learning model we create has to perform **better than 86.6%** to beat random chance.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the data:\n",
    "Since we're not ready to do anything with the message text, let's see if we can predict ham/spam labels based on message length and punctuation counts. We'll look at message `length` first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5572.000000\n",
       "mean       80.489950\n",
       "std        59.942907\n",
       "min         2.000000\n",
       "25%        36.000000\n",
       "50%        62.000000\n",
       "75%       122.000000\n",
       "max       910.000000\n",
       "Name: length, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['length'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=green>This dataset is extremely skewed. The mean value is 80.5 and yet the max length is 910. Let's plot this on a logarithmic x-axis.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.xscale('log')\n",
    "bins = 1.15**(np.arange(0,50))\n",
    "plt.hist(df[df['label']=='ham']['length'],bins=bins,alpha=0.8)\n",
    "plt.hist(df[df['label']=='spam']['length'],bins=bins,alpha=0.8)\n",
    "plt.legend(('ham','spam'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=green>It looks like there's a small range of values where a message is more likely to be spam than ham.</font>\n",
    "\n",
    "Now let's look at the `punct` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5572.000000\n",
       "mean        4.177495\n",
       "std         4.623919\n",
       "min         0.000000\n",
       "25%         2.000000\n",
       "50%         3.000000\n",
       "75%         6.000000\n",
       "max       133.000000\n",
       "Name: punct, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['punct'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xscale('log')\n",
    "bins = 1.5**(np.arange(0,15))\n",
    "plt.hist(df[df['label']=='ham']['punct'],bins=bins,alpha=0.8)\n",
    "plt.hist(df[df['label']=='spam']['punct'],bins=bins,alpha=0.8)\n",
    "plt.legend(('ham','spam'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=green>This looks even worse - there seem to be no values where one would pick spam over ham. We'll still try to build a machine learning classification model, but we should expect poor results.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Split the data into train & test sets:\n",
    "\n",
    "If we wanted to divide the DataFrame into two smaller sets, we could use\n",
    "> `train, test = train_test_split(df)`\n",
    "\n",
    "For our purposes let's also set up our Features (X) and Labels (y). The Label is simple - we're trying to predict the `label` column in our data. For Features we'll use the `length` and `punct` columns. *By convention, **X** is capitalized and **y** is lowercase.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting features\n",
    "There are two ways to build a feature set from the columns we want. If the number of features is small, then we can pass those in directly:\n",
    "> `X = df[['length','punct']]`\n",
    "\n",
    "If the number of features is large, then it may be easier to drop the Label and any other unwanted columns:\n",
    "> `X = df.drop(['label','message'], axis=1)`\n",
    "\n",
    "These operations make copies of **df**, but do not change the original DataFrame in place. All the original data is preserved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Feature and Label sets\n",
    "X = df[['length','punct']]  # note the double set of brackets\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional train/test/split arguments:\n",
    "The default test size for `train_test_split` is 30%. Here we'll assign 33% of the data for testing.<br>\n",
    "Also, we can set a `random_state` seed value to ensure that everyone uses the same \"random\" training & testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Shape: (3733, 2)\n",
      "Testing Data Shape:  (1839, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "print('Training Data Shape:', X_train.shape)\n",
    "print('Testing Data Shape: ', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can pass these sets into a series of different training & testing algorithms and compare their results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Train a Logistic Regression classifier\n",
    "One of the simplest multi-class classification tools is [logistic regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html). Scikit-learn offers a variety of algorithmic solvers; we'll use [L-BFGS](https://en.wikipedia.org/wiki/Limited-memory_BFGS). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_model = LogisticRegression(solver='lbfgs')\n",
    "\n",
    "lr_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Accuracy of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1547   46]\n",
      " [ 241    5]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# Create a prediction set:\n",
    "predictions = lr_model.predict(X_test)\n",
    "\n",
    "# Print a confusion matrix\n",
    "print(metrics.confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>ham</td>\n",
       "      <td>1547</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>spam</td>\n",
       "      <td>241</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ham  spam\n",
       "ham   1547    46\n",
       "spam   241     5"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can make the confusion matrix less confusing by adding labels:\n",
    "df = pd.DataFrame(metrics.confusion_matrix(y_test,predictions), index=['ham','spam'], columns=['ham','spam'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=green>These results are terrible! More spam messages were confused as ham (241) than correctly identified as spam (5), although a relatively small number of ham messages (46) were confused as spam.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.87      0.97      0.92      1593\n",
      "        spam       0.10      0.02      0.03       246\n",
      "\n",
      "    accuracy                           0.84      1839\n",
      "   macro avg       0.48      0.50      0.47      1839\n",
      "weighted avg       0.76      0.84      0.80      1839\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print a classification report\n",
    "print(metrics.classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.843936922240348\n"
     ]
    }
   ],
   "source": [
    "# Print the overall accuracy\n",
    "print(metrics.accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=green>This model performed *worse* than a classifier that assigned all messages as \"ham\" would have!</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Train a naïve Bayes classifier:\n",
    "One of the most common - and successful - classifiers is [naïve Bayes](http://scikit-learn.org/stable/modules/naive_bayes.html#naive-bayes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb_model = MultinomialNB()\n",
    "\n",
    "nb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run predictions and report on metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1583   10]\n",
      " [ 246    0]]\n"
     ]
    }
   ],
   "source": [
    "predictions = nb_model.predict(X_test)\n",
    "print(metrics.confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=green>The total number of confusions dropped from **287** to **256**. [241+46=287, 246+10=256]</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.87      0.99      0.93      1593\n",
      "        spam       0.00      0.00      0.00       246\n",
      "\n",
      "    accuracy                           0.86      1839\n",
      "   macro avg       0.43      0.50      0.46      1839\n",
      "weighted avg       0.75      0.86      0.80      1839\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8607939097335509\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=green>Better, but still less accurate than 86.6%</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Train a support vector machine (SVM) classifier\n",
    "Among the SVM options available, we'll use [C-Support Vector Classification (SVC)](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc_model = SVC(gamma='auto')\n",
    "svc_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run predictions and report on metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1515   78]\n",
      " [ 131  115]]\n"
     ]
    }
   ],
   "source": [
    "predictions = svc_model.predict(X_test)\n",
    "print(metrics.confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=green>The total number of confusions dropped even further to **131**.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.92      0.95      0.94      1593\n",
      "        spam       0.60      0.47      0.52       246\n",
      "\n",
      "    accuracy                           0.89      1839\n",
      "   macro avg       0.76      0.71      0.73      1839\n",
      "weighted avg       0.88      0.89      0.88      1839\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8863512778684067\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=green>And finally we have a model that performs *slightly* better than random chance.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now you should be able to load a dataset, divide it into training and testing sets, and perform simple analyses using scikit-learn."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
